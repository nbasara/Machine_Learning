{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWqHKEW6Hbqc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e593de680b6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "P1un9imJZOU5",
    "outputId": "0ffd9196-5f86-4ef1-dd88-30194a03cdd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iN3YtFWYcDAu",
    "outputId": "1adb22b5-1f9b-460e-eb8d-0a8aec8269f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/CSE142/ucsc-cse142-project-2-challenge-project.zip\n",
      "replace __MACOSX/._ucsc-cse142-project-2-challenge-project? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "INPUT = \"/content/ucsc-cse142-project-2-challenge-project/\"\n",
    "!unzip '/content/drive/My Drive/CSE142/ucsc-cse142-project-2-challenge-project.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "dm1KbkmAYpED",
    "outputId": "8ad891c1-8323-449c-83e5-a274463d0293"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_File_Name</th>\n",
       "      <th>Human_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_File_Name Human_Label\n",
       "0           0.png        frog\n",
       "1           1.png    airplane\n",
       "2           2.png       truck\n",
       "3           3.png        deer\n",
       "4           4.png        deer"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = pd.read_csv(INPUT + \"Train_Labels.csv\")\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7F73b-mjaMoa",
    "outputId": "c06e9bcf-7bd4-4317-8d55-bbcfca4a1d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane' 'automobile' 'bird' 'cat' 'deer' 'dog' 'frog' 'horse' 'ship'\n",
      " 'truck']\n"
     ]
    }
   ],
   "source": [
    "label = trainData.Human_Label.values\n",
    "myLabels = np.unique(label)\n",
    "print(myLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "ddLQNq_x3fC_",
    "outputId": "e0846461-2f6e-4d2e-b88c-c2b35125caf1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_File_Name</th>\n",
       "      <th>Human_Label</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>frog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>deer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>deer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995.png</td>\n",
       "      <td>cat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997.png</td>\n",
       "      <td>automobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998.png</td>\n",
       "      <td>automobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999.png</td>\n",
       "      <td>dog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_File_Name Human_Label  airplane  ...  horse  ship  truck\n",
       "0              0.png        frog         0  ...      0     0      0\n",
       "1              1.png    airplane         0  ...      0     0      0\n",
       "2              2.png       truck         0  ...      0     0      0\n",
       "3              3.png        deer         0  ...      0     0      0\n",
       "4              4.png        deer         0  ...      0     0      0\n",
       "...              ...         ...       ...  ...    ...   ...    ...\n",
       "9995        9995.png         cat         0  ...      0     0      0\n",
       "9996        9996.png       truck         0  ...      0     0      0\n",
       "9997        9997.png  automobile         0  ...      0     0      0\n",
       "9998        9998.png  automobile         0  ...      0     0      0\n",
       "9999        9999.png         dog         0  ...      0     0      0\n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for labels in myLabels:\n",
    "  trainData[labels] = 0\n",
    "trainData\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "colab_type": "code",
    "id": "Vlgj6uhiJZ4q",
    "outputId": "29425cd5-3020-4f07-9b4e-84f2289634d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_File_Name</th>\n",
       "      <th>Human_Label</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>frog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>deer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>deer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995.png</td>\n",
       "      <td>cat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997.png</td>\n",
       "      <td>automobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998.png</td>\n",
       "      <td>automobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999.png</td>\n",
       "      <td>dog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_File_Name Human_Label  airplane  ...  horse  ship  truck\n",
       "0              0.png        frog         0  ...      0     0      0\n",
       "1              1.png    airplane         1  ...      0     0      0\n",
       "2              2.png       truck         0  ...      0     0      1\n",
       "3              3.png        deer         0  ...      0     0      0\n",
       "4              4.png        deer         0  ...      0     0      0\n",
       "...              ...         ...       ...  ...    ...   ...    ...\n",
       "9995        9995.png         cat         0  ...      0     0      0\n",
       "9996        9996.png       truck         0  ...      0     0      1\n",
       "9997        9997.png  automobile         0  ...      0     0      0\n",
       "9998        9998.png  automobile         0  ...      0     0      0\n",
       "9999        9999.png         dog         0  ...      0     0      0\n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(trainData)):\n",
    "  x = trainData.Human_Label[i]\n",
    "  trainData[x][i] = 1\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "95ER8tTTLVTz",
    "outputId": "b09e6162-5524-4025-ede6-f1fec8b11fdc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n",
       "0            0           0     0    0     0    0     1      0     0      0\n",
       "1            1           0     0    0     0    0     0      0     0      0\n",
       "2            0           0     0    0     0    0     0      0     0      1\n",
       "3            0           0     0    0     1    0     0      0     0      0\n",
       "4            0           0     0    0     1    0     0      0     0      0\n",
       "...        ...         ...   ...  ...   ...  ...   ...    ...   ...    ...\n",
       "9995         0           0     0    1     0    0     0      0     0      0\n",
       "9996         0           0     0    0     0    0     0      0     0      1\n",
       "9997         0           1     0    0     0    0     0      0     0      0\n",
       "9998         0           1     0    0     0    0     0      0     0      0\n",
       "9999         0           0     0    0     0    1     0      0     0      0\n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels = trainData.drop(columns=[\"Image_File_Name\", \"Human_Label\"])\n",
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tAcBu03ndyk2",
    "outputId": "6895befc-d2f3-4a23-9af0-22746db002e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "trainImages = \"/content/ucsc-cse142-project-2-challenge-project/Train_Image/Final_Train_Image/\"\n",
    "file_path = []\n",
    "y = []\n",
    "for i in range(9999):\n",
    "  file_path.append(trainImages+trainData.Image_File_Name[i])\n",
    "  y.append(Labels.loc[i])\n",
    "y = np.array(y)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KM2jNT-kPoUh"
   },
   "outputs": [],
   "source": [
    "trainImages = \"/content/ucsc-cse142-project-2-challenge-project/Train_Image/Final_Train_Image/\"\n",
    "test_file_path = []\n",
    "test_y = []\n",
    "for i in range(9000, 9999):\n",
    "  test_file_path.append(trainImages+trainData.Image_File_Name[i])\n",
    "  test_y.append(Labels.loc[i])\n",
    "test_y = np.array(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmpc0mKxu5vk"
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "for i, myPath in enumerate(file_path):\n",
    "    img = cv2.imread(myPath)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = img[16:240, 16:240]\n",
    "    x.append(img)\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rBv6jLkQKLZ"
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for i, myPath in enumerate(test_file_path):\n",
    "    img = cv2.imread(myPath)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = img[16:240, 16:240]\n",
    "    x_test.append(img)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5MFXishV9rq2",
    "outputId": "705c2524-e855-4bc5-93cb-660677dac8f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictImages = \"/content/ucsc-cse142-project-2-challenge-project/Test_Image/Test_Image/\"\n",
    "#                /content/ucsc-cse142-project-2-challenge-project/Test_Image/Test_Image/0.png\n",
    "predict_file_path = []\n",
    "for i in range(1000):\n",
    "  predict_file_path.append(predictImages+str(i)+\".png\")\n",
    "len(predict_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L_TchU2f-vnR",
    "outputId": "ff9d01a2-97ef-4b7a-ab1d-5173f3c0ff92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_predict = []\n",
    "for i, myPath in enumerate(predict_file_path):\n",
    "    img = cv2.imread(myPath)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = img[16:240, 16:240]\n",
    "    my_predict.append(img)\n",
    "my_predict = np.array(my_predict)\n",
    "my_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iTmFcZHHxKNf",
    "outputId": "00dddd8f-997a-4962-81ed-35e7641319b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "valid_images = len(x)\n",
    "random_num = np.random.permutation(valid_images)\n",
    "x_ran = []\n",
    "y_ran = []\n",
    "\n",
    "for i in range(valid_images):\n",
    "  x_ran.append(x[random_num[i]])\n",
    "  y_ran.append(y[random_num[i]])\n",
    "\n",
    "x = np.array(x_ran)\n",
    "y = np.array(y_ran)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zDER3HCAxwwo",
    "outputId": "f3f118ab-1142-4427-abd4-af7f17667b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (8999, 32, 32, 3)\n",
      "y_train (8999, 10)\n",
      "x_test (1000, 32, 32, 3)\n",
      "y_test (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "val_split_num = int(round(.1*len(y)))\n",
    "x_train = x[val_split_num:]\n",
    "y_train = y[val_split_num:]\n",
    "\n",
    "x_test = x[:val_split_num]\n",
    "y_test = y[:val_split_num]\n",
    "\n",
    "print('x_train', x_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('x_test', x_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouMWfj2COpDN"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "my_predict = my_predict.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "my_predict /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9_V8Og2EO1cX",
    "outputId": "65974235-8f7c-41fe-e06a-c3e45f8294d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "img_rows, img_cols, img_channel = 32, 32, 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "WLU3zB2cPA0f",
    "outputId": "abad8521-3238-482e-f720-a19d4d20a5df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 550,570\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def define_model():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "  #opt = SGD(lr=0.001, momentum=0.9) now using adam default values\n",
    "  model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "model = define_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UQpBLwOxPGV1",
    "outputId": "71f24b67-a854-4d1f-c800-283a15fdf30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/250\n",
      "71/71 [==============================] - 7s 100ms/step - loss: 3.1851 - accuracy: 0.1592 - val_loss: 2.7903 - val_accuracy: 0.2580\n",
      "Epoch 2/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 2.7045 - accuracy: 0.2738 - val_loss: 2.5394 - val_accuracy: 0.3220\n",
      "Epoch 3/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 2.4947 - accuracy: 0.3213 - val_loss: 2.4318 - val_accuracy: 0.3390\n",
      "Epoch 4/250\n",
      "71/71 [==============================] - 7s 99ms/step - loss: 2.3531 - accuracy: 0.3585 - val_loss: 2.2741 - val_accuracy: 0.3730\n",
      "Epoch 5/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 2.2835 - accuracy: 0.3723 - val_loss: 2.1993 - val_accuracy: 0.4170\n",
      "Epoch 6/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 2.2004 - accuracy: 0.3929 - val_loss: 2.0761 - val_accuracy: 0.4420\n",
      "Epoch 7/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 2.1393 - accuracy: 0.4089 - val_loss: 2.0227 - val_accuracy: 0.4730\n",
      "Epoch 8/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 2.0930 - accuracy: 0.4212 - val_loss: 2.0014 - val_accuracy: 0.4660\n",
      "Epoch 9/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 2.0451 - accuracy: 0.4363 - val_loss: 1.9894 - val_accuracy: 0.4570\n",
      "Epoch 10/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 2.0079 - accuracy: 0.4417 - val_loss: 1.9706 - val_accuracy: 0.4520\n",
      "Epoch 11/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.9857 - accuracy: 0.4478 - val_loss: 1.9665 - val_accuracy: 0.4500\n",
      "Epoch 12/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.9498 - accuracy: 0.4592 - val_loss: 1.8544 - val_accuracy: 0.5010\n",
      "Epoch 13/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.9076 - accuracy: 0.4773 - val_loss: 1.8246 - val_accuracy: 0.4960\n",
      "Epoch 14/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.8749 - accuracy: 0.4919 - val_loss: 1.8434 - val_accuracy: 0.4920\n",
      "Epoch 15/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.8550 - accuracy: 0.4985 - val_loss: 1.8283 - val_accuracy: 0.4990\n",
      "Epoch 16/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.8402 - accuracy: 0.5018 - val_loss: 1.8293 - val_accuracy: 0.5110\n",
      "Epoch 17/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.7970 - accuracy: 0.5161 - val_loss: 1.7838 - val_accuracy: 0.5230\n",
      "Epoch 18/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.7866 - accuracy: 0.5236 - val_loss: 1.7452 - val_accuracy: 0.5310\n",
      "Epoch 19/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.7867 - accuracy: 0.5184 - val_loss: 1.7183 - val_accuracy: 0.5530\n",
      "Epoch 20/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.7426 - accuracy: 0.5372 - val_loss: 1.7469 - val_accuracy: 0.5530\n",
      "Epoch 21/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.7297 - accuracy: 0.5474 - val_loss: 1.7352 - val_accuracy: 0.5400\n",
      "Epoch 22/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.7357 - accuracy: 0.5429 - val_loss: 1.7315 - val_accuracy: 0.5500\n",
      "Epoch 23/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.6995 - accuracy: 0.5540 - val_loss: 1.6859 - val_accuracy: 0.5630\n",
      "Epoch 24/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.6908 - accuracy: 0.5575 - val_loss: 1.7610 - val_accuracy: 0.5350\n",
      "Epoch 25/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.6883 - accuracy: 0.5617 - val_loss: 1.6816 - val_accuracy: 0.5650\n",
      "Epoch 26/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.6827 - accuracy: 0.5596 - val_loss: 1.6900 - val_accuracy: 0.5670\n",
      "Epoch 27/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.6652 - accuracy: 0.5703 - val_loss: 1.7239 - val_accuracy: 0.5490\n",
      "Epoch 28/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.6453 - accuracy: 0.5806 - val_loss: 1.6560 - val_accuracy: 0.5830\n",
      "Epoch 29/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.6525 - accuracy: 0.5737 - val_loss: 1.7185 - val_accuracy: 0.5690\n",
      "Epoch 30/250\n",
      "71/71 [==============================] - 7s 99ms/step - loss: 1.6309 - accuracy: 0.5815 - val_loss: 1.6909 - val_accuracy: 0.5680\n",
      "Epoch 31/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.6337 - accuracy: 0.5833 - val_loss: 1.6992 - val_accuracy: 0.5730\n",
      "Epoch 32/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.6277 - accuracy: 0.5814 - val_loss: 1.7430 - val_accuracy: 0.5490\n",
      "Epoch 33/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.6021 - accuracy: 0.5964 - val_loss: 1.7217 - val_accuracy: 0.5650\n",
      "Epoch 34/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.6070 - accuracy: 0.5990 - val_loss: 1.7047 - val_accuracy: 0.5770\n",
      "Epoch 35/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.5728 - accuracy: 0.6030 - val_loss: 1.7718 - val_accuracy: 0.5640\n",
      "Epoch 36/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.5780 - accuracy: 0.6055 - val_loss: 1.7263 - val_accuracy: 0.5790\n",
      "Epoch 37/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.5707 - accuracy: 0.6134 - val_loss: 1.7282 - val_accuracy: 0.5760\n",
      "Epoch 38/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.5510 - accuracy: 0.6202 - val_loss: 1.7170 - val_accuracy: 0.5890\n",
      "Epoch 39/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.5389 - accuracy: 0.6207 - val_loss: 1.8108 - val_accuracy: 0.5530\n",
      "Epoch 40/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.5463 - accuracy: 0.6188 - val_loss: 1.7143 - val_accuracy: 0.5780\n",
      "Epoch 41/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.5361 - accuracy: 0.6208 - val_loss: 1.7517 - val_accuracy: 0.5700\n",
      "Epoch 42/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.5307 - accuracy: 0.6286 - val_loss: 1.7282 - val_accuracy: 0.5940\n",
      "Epoch 43/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.4940 - accuracy: 0.6381 - val_loss: 1.7827 - val_accuracy: 0.5860\n",
      "Epoch 44/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.5228 - accuracy: 0.6297 - val_loss: 1.7823 - val_accuracy: 0.5770\n",
      "Epoch 45/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.5154 - accuracy: 0.6274 - val_loss: 1.8255 - val_accuracy: 0.5650\n",
      "Epoch 46/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.5234 - accuracy: 0.6274 - val_loss: 1.7565 - val_accuracy: 0.5990\n",
      "Epoch 47/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.4993 - accuracy: 0.6386 - val_loss: 1.7866 - val_accuracy: 0.5840\n",
      "Epoch 48/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.4753 - accuracy: 0.6471 - val_loss: 1.8388 - val_accuracy: 0.5830\n",
      "Epoch 49/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.4686 - accuracy: 0.6530 - val_loss: 1.8070 - val_accuracy: 0.5840\n",
      "Epoch 50/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.4691 - accuracy: 0.6516 - val_loss: 1.8193 - val_accuracy: 0.5820\n",
      "Epoch 51/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.4598 - accuracy: 0.6567 - val_loss: 1.8295 - val_accuracy: 0.5560\n",
      "Epoch 52/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.4482 - accuracy: 0.6589 - val_loss: 1.9026 - val_accuracy: 0.5670\n",
      "Epoch 53/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.4574 - accuracy: 0.6477 - val_loss: 1.8212 - val_accuracy: 0.5850\n",
      "Epoch 54/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.4280 - accuracy: 0.6634 - val_loss: 1.8325 - val_accuracy: 0.5700\n",
      "Epoch 55/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.4372 - accuracy: 0.6571 - val_loss: 1.8747 - val_accuracy: 0.5720\n",
      "Epoch 56/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.4236 - accuracy: 0.6676 - val_loss: 1.8675 - val_accuracy: 0.5660\n",
      "Epoch 57/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.4251 - accuracy: 0.6625 - val_loss: 1.8630 - val_accuracy: 0.5760\n",
      "Epoch 58/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.4221 - accuracy: 0.6681 - val_loss: 1.9301 - val_accuracy: 0.5640\n",
      "Epoch 59/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.4122 - accuracy: 0.6774 - val_loss: 1.8774 - val_accuracy: 0.5680\n",
      "Epoch 60/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.3966 - accuracy: 0.6762 - val_loss: 1.9560 - val_accuracy: 0.5620\n",
      "Epoch 61/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.3812 - accuracy: 0.6839 - val_loss: 1.8777 - val_accuracy: 0.5840\n",
      "Epoch 62/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.4032 - accuracy: 0.6735 - val_loss: 1.9297 - val_accuracy: 0.5620\n",
      "Epoch 63/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.3763 - accuracy: 0.6820 - val_loss: 1.8845 - val_accuracy: 0.5910\n",
      "Epoch 64/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.3600 - accuracy: 0.6833 - val_loss: 1.9228 - val_accuracy: 0.5680\n",
      "Epoch 65/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.3541 - accuracy: 0.6920 - val_loss: 2.0230 - val_accuracy: 0.5650\n",
      "Epoch 66/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.3654 - accuracy: 0.6911 - val_loss: 1.9150 - val_accuracy: 0.5750\n",
      "Epoch 67/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.3595 - accuracy: 0.6947 - val_loss: 1.9940 - val_accuracy: 0.5860\n",
      "Epoch 68/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.3348 - accuracy: 0.6956 - val_loss: 2.0630 - val_accuracy: 0.5650\n",
      "Epoch 69/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.3450 - accuracy: 0.6940 - val_loss: 1.9772 - val_accuracy: 0.5690\n",
      "Epoch 70/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.3452 - accuracy: 0.6954 - val_loss: 1.9728 - val_accuracy: 0.5660\n",
      "Epoch 71/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.3387 - accuracy: 0.7051 - val_loss: 2.0324 - val_accuracy: 0.5710\n",
      "Epoch 72/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.3236 - accuracy: 0.7052 - val_loss: 2.0159 - val_accuracy: 0.5820\n",
      "Epoch 73/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.3083 - accuracy: 0.7120 - val_loss: 2.0668 - val_accuracy: 0.5460\n",
      "Epoch 74/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.3071 - accuracy: 0.7109 - val_loss: 2.0693 - val_accuracy: 0.5420\n",
      "Epoch 75/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.3035 - accuracy: 0.7134 - val_loss: 2.1337 - val_accuracy: 0.5520\n",
      "Epoch 76/250\n",
      "71/71 [==============================] - 7s 99ms/step - loss: 1.3119 - accuracy: 0.7055 - val_loss: 2.0494 - val_accuracy: 0.5560\n",
      "Epoch 77/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.2960 - accuracy: 0.7160 - val_loss: 2.0649 - val_accuracy: 0.5580\n",
      "Epoch 78/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.2878 - accuracy: 0.7175 - val_loss: 2.0488 - val_accuracy: 0.5580\n",
      "Epoch 79/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.2664 - accuracy: 0.7253 - val_loss: 2.1231 - val_accuracy: 0.5650\n",
      "Epoch 80/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.2815 - accuracy: 0.7186 - val_loss: 2.1257 - val_accuracy: 0.5430\n",
      "Epoch 81/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.2747 - accuracy: 0.7203 - val_loss: 2.1530 - val_accuracy: 0.5580\n",
      "Epoch 82/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.2839 - accuracy: 0.7237 - val_loss: 2.1009 - val_accuracy: 0.5850\n",
      "Epoch 83/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.2508 - accuracy: 0.7382 - val_loss: 2.1451 - val_accuracy: 0.5560\n",
      "Epoch 84/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.2685 - accuracy: 0.7242 - val_loss: 2.1313 - val_accuracy: 0.5760\n",
      "Epoch 85/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.2624 - accuracy: 0.7262 - val_loss: 2.1234 - val_accuracy: 0.5570\n",
      "Epoch 86/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.2344 - accuracy: 0.7447 - val_loss: 2.1681 - val_accuracy: 0.5670\n",
      "Epoch 87/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.2421 - accuracy: 0.7377 - val_loss: 2.2141 - val_accuracy: 0.5550\n",
      "Epoch 88/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.2540 - accuracy: 0.7333 - val_loss: 2.1918 - val_accuracy: 0.5500\n",
      "Epoch 89/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.2268 - accuracy: 0.7420 - val_loss: 2.1412 - val_accuracy: 0.5540\n",
      "Epoch 90/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.2194 - accuracy: 0.7433 - val_loss: 2.2516 - val_accuracy: 0.5580\n",
      "Epoch 91/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.2566 - accuracy: 0.7274 - val_loss: 2.1762 - val_accuracy: 0.5440\n",
      "Epoch 92/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.2021 - accuracy: 0.7540 - val_loss: 2.2915 - val_accuracy: 0.5370\n",
      "Epoch 93/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.2287 - accuracy: 0.7467 - val_loss: 2.2204 - val_accuracy: 0.5410\n",
      "Epoch 94/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.2132 - accuracy: 0.7494 - val_loss: 2.3523 - val_accuracy: 0.5460\n",
      "Epoch 95/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1998 - accuracy: 0.7534 - val_loss: 2.2851 - val_accuracy: 0.5450\n",
      "Epoch 96/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1961 - accuracy: 0.7508 - val_loss: 2.2499 - val_accuracy: 0.5590\n",
      "Epoch 97/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.2230 - accuracy: 0.7460 - val_loss: 2.3425 - val_accuracy: 0.5750\n",
      "Epoch 98/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1936 - accuracy: 0.7582 - val_loss: 2.3103 - val_accuracy: 0.5680\n",
      "Epoch 99/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1713 - accuracy: 0.7675 - val_loss: 2.2657 - val_accuracy: 0.5570\n",
      "Epoch 100/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.2066 - accuracy: 0.7512 - val_loss: 2.3027 - val_accuracy: 0.5480\n",
      "Epoch 101/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1905 - accuracy: 0.7621 - val_loss: 2.3216 - val_accuracy: 0.5520\n",
      "Epoch 102/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1714 - accuracy: 0.7658 - val_loss: 2.2675 - val_accuracy: 0.5590\n",
      "Epoch 103/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1782 - accuracy: 0.7641 - val_loss: 2.3439 - val_accuracy: 0.5240\n",
      "Epoch 104/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1848 - accuracy: 0.7625 - val_loss: 2.3324 - val_accuracy: 0.5440\n",
      "Epoch 105/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1646 - accuracy: 0.7650 - val_loss: 2.4447 - val_accuracy: 0.5530\n",
      "Epoch 106/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1563 - accuracy: 0.7770 - val_loss: 2.3667 - val_accuracy: 0.5660\n",
      "Epoch 107/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1389 - accuracy: 0.7781 - val_loss: 2.3958 - val_accuracy: 0.5540\n",
      "Epoch 108/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1750 - accuracy: 0.7688 - val_loss: 2.3434 - val_accuracy: 0.5450\n",
      "Epoch 109/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.2002 - accuracy: 0.7592 - val_loss: 2.3633 - val_accuracy: 0.5430\n",
      "Epoch 110/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1514 - accuracy: 0.7751 - val_loss: 2.3753 - val_accuracy: 0.5610\n",
      "Epoch 111/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.1564 - accuracy: 0.7716 - val_loss: 2.4479 - val_accuracy: 0.5440\n",
      "Epoch 112/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1579 - accuracy: 0.7780 - val_loss: 2.4316 - val_accuracy: 0.5500\n",
      "Epoch 113/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1483 - accuracy: 0.7716 - val_loss: 2.3700 - val_accuracy: 0.5530\n",
      "Epoch 114/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1381 - accuracy: 0.7808 - val_loss: 2.5228 - val_accuracy: 0.5580\n",
      "Epoch 115/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1172 - accuracy: 0.7885 - val_loss: 2.5103 - val_accuracy: 0.5310\n",
      "Epoch 116/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1411 - accuracy: 0.7740 - val_loss: 2.4293 - val_accuracy: 0.5610\n",
      "Epoch 117/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.1179 - accuracy: 0.7879 - val_loss: 2.4802 - val_accuracy: 0.5640\n",
      "Epoch 118/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.1429 - accuracy: 0.7803 - val_loss: 2.5179 - val_accuracy: 0.5480\n",
      "Epoch 119/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1331 - accuracy: 0.7803 - val_loss: 2.5113 - val_accuracy: 0.5460\n",
      "Epoch 120/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.1170 - accuracy: 0.7948 - val_loss: 2.5513 - val_accuracy: 0.5450\n",
      "Epoch 121/250\n",
      "71/71 [==============================] - 7s 99ms/step - loss: 1.1190 - accuracy: 0.7883 - val_loss: 2.5249 - val_accuracy: 0.5390\n",
      "Epoch 122/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1060 - accuracy: 0.7930 - val_loss: 2.5376 - val_accuracy: 0.5300\n",
      "Epoch 123/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.1187 - accuracy: 0.7870 - val_loss: 2.6017 - val_accuracy: 0.5440\n",
      "Epoch 124/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.1141 - accuracy: 0.7874 - val_loss: 2.4584 - val_accuracy: 0.5290\n",
      "Epoch 125/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.1034 - accuracy: 0.7939 - val_loss: 2.6590 - val_accuracy: 0.5360\n",
      "Epoch 126/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.1213 - accuracy: 0.7864 - val_loss: 2.5296 - val_accuracy: 0.5480\n",
      "Epoch 127/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.1158 - accuracy: 0.7894 - val_loss: 2.4756 - val_accuracy: 0.5150\n",
      "Epoch 128/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1336 - accuracy: 0.7866 - val_loss: 2.5865 - val_accuracy: 0.5430\n",
      "Epoch 129/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0948 - accuracy: 0.7990 - val_loss: 2.5778 - val_accuracy: 0.5310\n",
      "Epoch 130/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1114 - accuracy: 0.7919 - val_loss: 2.5203 - val_accuracy: 0.5610\n",
      "Epoch 131/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0981 - accuracy: 0.7944 - val_loss: 2.5542 - val_accuracy: 0.5340\n",
      "Epoch 132/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0803 - accuracy: 0.8026 - val_loss: 2.6387 - val_accuracy: 0.5380\n",
      "Epoch 133/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0926 - accuracy: 0.7981 - val_loss: 2.5966 - val_accuracy: 0.5570\n",
      "Epoch 134/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.1066 - accuracy: 0.7924 - val_loss: 2.6379 - val_accuracy: 0.5360\n",
      "Epoch 135/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.0922 - accuracy: 0.7983 - val_loss: 2.5989 - val_accuracy: 0.5430\n",
      "Epoch 136/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0659 - accuracy: 0.8076 - val_loss: 2.5759 - val_accuracy: 0.5320\n",
      "Epoch 137/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0909 - accuracy: 0.7944 - val_loss: 2.5218 - val_accuracy: 0.5340\n",
      "Epoch 138/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0794 - accuracy: 0.8046 - val_loss: 2.6575 - val_accuracy: 0.5490\n",
      "Epoch 139/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0882 - accuracy: 0.7964 - val_loss: 2.6126 - val_accuracy: 0.5270\n",
      "Epoch 140/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0758 - accuracy: 0.8053 - val_loss: 2.5704 - val_accuracy: 0.5630\n",
      "Epoch 141/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0907 - accuracy: 0.8005 - val_loss: 2.5659 - val_accuracy: 0.5240\n",
      "Epoch 142/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.0736 - accuracy: 0.8093 - val_loss: 2.6374 - val_accuracy: 0.5480\n",
      "Epoch 143/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0700 - accuracy: 0.8091 - val_loss: 2.5700 - val_accuracy: 0.5420\n",
      "Epoch 144/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.0877 - accuracy: 0.8056 - val_loss: 2.6074 - val_accuracy: 0.5450\n",
      "Epoch 145/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0484 - accuracy: 0.8142 - val_loss: 2.6688 - val_accuracy: 0.5450\n",
      "Epoch 146/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0665 - accuracy: 0.8050 - val_loss: 2.5516 - val_accuracy: 0.5360\n",
      "Epoch 147/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0812 - accuracy: 0.8058 - val_loss: 2.5794 - val_accuracy: 0.5500\n",
      "Epoch 148/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0634 - accuracy: 0.8119 - val_loss: 2.7412 - val_accuracy: 0.5430\n",
      "Epoch 149/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0556 - accuracy: 0.8101 - val_loss: 2.7129 - val_accuracy: 0.5280\n",
      "Epoch 150/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0686 - accuracy: 0.8091 - val_loss: 2.6607 - val_accuracy: 0.5410\n",
      "Epoch 151/250\n",
      "71/71 [==============================] - 6s 91ms/step - loss: 1.0610 - accuracy: 0.8051 - val_loss: 2.7137 - val_accuracy: 0.5200\n",
      "Epoch 152/250\n",
      "71/71 [==============================] - 7s 92ms/step - loss: 1.0405 - accuracy: 0.8212 - val_loss: 2.6204 - val_accuracy: 0.5450\n",
      "Epoch 153/250\n",
      "71/71 [==============================] - 6s 91ms/step - loss: 1.0752 - accuracy: 0.8068 - val_loss: 2.5758 - val_accuracy: 0.5490\n",
      "Epoch 154/250\n",
      "71/71 [==============================] - 7s 92ms/step - loss: 1.0507 - accuracy: 0.8108 - val_loss: 2.6597 - val_accuracy: 0.5260\n",
      "Epoch 155/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0772 - accuracy: 0.8046 - val_loss: 2.5707 - val_accuracy: 0.5520\n",
      "Epoch 156/250\n",
      "71/71 [==============================] - 6s 90ms/step - loss: 1.0662 - accuracy: 0.8105 - val_loss: 2.6493 - val_accuracy: 0.5250\n",
      "Epoch 157/250\n",
      "71/71 [==============================] - 7s 92ms/step - loss: 1.0435 - accuracy: 0.8203 - val_loss: 2.6039 - val_accuracy: 0.5450\n",
      "Epoch 158/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0526 - accuracy: 0.8113 - val_loss: 2.6884 - val_accuracy: 0.5340\n",
      "Epoch 159/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0505 - accuracy: 0.8155 - val_loss: 2.5426 - val_accuracy: 0.5490\n",
      "Epoch 160/250\n",
      "71/71 [==============================] - 6s 91ms/step - loss: 1.0212 - accuracy: 0.8269 - val_loss: 2.7248 - val_accuracy: 0.5450\n",
      "Epoch 161/250\n",
      "71/71 [==============================] - 7s 92ms/step - loss: 1.0561 - accuracy: 0.8130 - val_loss: 2.6280 - val_accuracy: 0.5450\n",
      "Epoch 162/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0497 - accuracy: 0.8139 - val_loss: 2.6810 - val_accuracy: 0.5370\n",
      "Epoch 163/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.0520 - accuracy: 0.8141 - val_loss: 2.7065 - val_accuracy: 0.5240\n",
      "Epoch 164/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0320 - accuracy: 0.8232 - val_loss: 2.7080 - val_accuracy: 0.5470\n",
      "Epoch 165/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0465 - accuracy: 0.8205 - val_loss: 2.6996 - val_accuracy: 0.5250\n",
      "Epoch 166/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0612 - accuracy: 0.8131 - val_loss: 2.6403 - val_accuracy: 0.5510\n",
      "Epoch 167/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.0398 - accuracy: 0.8220 - val_loss: 2.6708 - val_accuracy: 0.5470\n",
      "Epoch 168/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.0115 - accuracy: 0.8292 - val_loss: 2.6511 - val_accuracy: 0.5470\n",
      "Epoch 169/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0235 - accuracy: 0.8205 - val_loss: 2.7151 - val_accuracy: 0.5270\n",
      "Epoch 170/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0424 - accuracy: 0.8219 - val_loss: 2.6415 - val_accuracy: 0.5430\n",
      "Epoch 171/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0442 - accuracy: 0.8191 - val_loss: 2.7155 - val_accuracy: 0.5520\n",
      "Epoch 172/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0330 - accuracy: 0.8246 - val_loss: 2.6996 - val_accuracy: 0.5140\n",
      "Epoch 173/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0342 - accuracy: 0.8259 - val_loss: 2.7758 - val_accuracy: 0.5340\n",
      "Epoch 174/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0228 - accuracy: 0.8274 - val_loss: 2.7593 - val_accuracy: 0.5110\n",
      "Epoch 175/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0468 - accuracy: 0.8212 - val_loss: 2.6251 - val_accuracy: 0.5410\n",
      "Epoch 176/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0202 - accuracy: 0.8271 - val_loss: 2.8284 - val_accuracy: 0.5490\n",
      "Epoch 177/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0298 - accuracy: 0.8236 - val_loss: 2.7789 - val_accuracy: 0.5110\n",
      "Epoch 178/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0378 - accuracy: 0.8208 - val_loss: 2.6328 - val_accuracy: 0.5590\n",
      "Epoch 179/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0217 - accuracy: 0.8252 - val_loss: 2.7171 - val_accuracy: 0.5200\n",
      "Epoch 180/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.0238 - accuracy: 0.8301 - val_loss: 2.7455 - val_accuracy: 0.5660\n",
      "Epoch 181/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0221 - accuracy: 0.8279 - val_loss: 2.7361 - val_accuracy: 0.5390\n",
      "Epoch 182/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0472 - accuracy: 0.8203 - val_loss: 2.8087 - val_accuracy: 0.5140\n",
      "Epoch 183/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0239 - accuracy: 0.8272 - val_loss: 2.6463 - val_accuracy: 0.5400\n",
      "Epoch 184/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0226 - accuracy: 0.8255 - val_loss: 2.6218 - val_accuracy: 0.5360\n",
      "Epoch 185/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0100 - accuracy: 0.8330 - val_loss: 2.7173 - val_accuracy: 0.5440\n",
      "Epoch 186/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0199 - accuracy: 0.8248 - val_loss: 2.6940 - val_accuracy: 0.5210\n",
      "Epoch 187/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0227 - accuracy: 0.8249 - val_loss: 2.7200 - val_accuracy: 0.5420\n",
      "Epoch 188/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 0.9998 - accuracy: 0.8364 - val_loss: 2.8154 - val_accuracy: 0.5390\n",
      "Epoch 189/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0460 - accuracy: 0.8105 - val_loss: 2.6281 - val_accuracy: 0.5480\n",
      "Epoch 190/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0073 - accuracy: 0.8385 - val_loss: 2.8638 - val_accuracy: 0.5290\n",
      "Epoch 191/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0300 - accuracy: 0.8236 - val_loss: 2.6698 - val_accuracy: 0.5250\n",
      "Epoch 192/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0102 - accuracy: 0.8343 - val_loss: 2.7683 - val_accuracy: 0.5150\n",
      "Epoch 193/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0167 - accuracy: 0.8309 - val_loss: 2.6991 - val_accuracy: 0.5240\n",
      "Epoch 194/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0120 - accuracy: 0.8293 - val_loss: 2.6859 - val_accuracy: 0.5460\n",
      "Epoch 195/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0298 - accuracy: 0.8249 - val_loss: 2.6610 - val_accuracy: 0.5460\n",
      "Epoch 196/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 1.0240 - accuracy: 0.8266 - val_loss: 2.6754 - val_accuracy: 0.5660\n",
      "Epoch 197/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0083 - accuracy: 0.8290 - val_loss: 2.7402 - val_accuracy: 0.5370\n",
      "Epoch 198/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 0.9951 - accuracy: 0.8362 - val_loss: 2.8157 - val_accuracy: 0.5340\n",
      "Epoch 199/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0066 - accuracy: 0.8328 - val_loss: 2.7709 - val_accuracy: 0.5360\n",
      "Epoch 200/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0143 - accuracy: 0.8351 - val_loss: 2.6257 - val_accuracy: 0.5530\n",
      "Epoch 201/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 1.0073 - accuracy: 0.8359 - val_loss: 2.7400 - val_accuracy: 0.5310\n",
      "Epoch 202/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 1.0190 - accuracy: 0.8298 - val_loss: 2.7989 - val_accuracy: 0.5380\n",
      "Epoch 203/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 0.9828 - accuracy: 0.8445 - val_loss: 2.7757 - val_accuracy: 0.5230\n",
      "Epoch 204/250\n",
      "71/71 [==============================] - 8s 115ms/step - loss: 0.9896 - accuracy: 0.8374 - val_loss: 2.7799 - val_accuracy: 0.5560\n",
      "Epoch 205/250\n",
      "71/71 [==============================] - 7s 101ms/step - loss: 1.0042 - accuracy: 0.8341 - val_loss: 2.8443 - val_accuracy: 0.5330\n",
      "Epoch 206/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 0.9993 - accuracy: 0.8320 - val_loss: 2.7402 - val_accuracy: 0.5560\n",
      "Epoch 207/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.0003 - accuracy: 0.8345 - val_loss: 2.8671 - val_accuracy: 0.5570\n",
      "Epoch 208/250\n",
      "71/71 [==============================] - 7s 99ms/step - loss: 1.0088 - accuracy: 0.8333 - val_loss: 2.7942 - val_accuracy: 0.5540\n",
      "Epoch 209/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.0040 - accuracy: 0.8339 - val_loss: 2.7632 - val_accuracy: 0.5310\n",
      "Epoch 210/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.0213 - accuracy: 0.8283 - val_loss: 2.6951 - val_accuracy: 0.5400\n",
      "Epoch 211/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.0072 - accuracy: 0.8356 - val_loss: 2.7760 - val_accuracy: 0.5350\n",
      "Epoch 212/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.0046 - accuracy: 0.8359 - val_loss: 2.7973 - val_accuracy: 0.5640\n",
      "Epoch 213/250\n",
      "71/71 [==============================] - 7s 101ms/step - loss: 0.9910 - accuracy: 0.8449 - val_loss: 2.8082 - val_accuracy: 0.5420\n",
      "Epoch 214/250\n",
      "71/71 [==============================] - 7s 100ms/step - loss: 0.9905 - accuracy: 0.8426 - val_loss: 2.7519 - val_accuracy: 0.5180\n",
      "Epoch 215/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.0020 - accuracy: 0.8363 - val_loss: 2.6903 - val_accuracy: 0.5440\n",
      "Epoch 216/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 0.9803 - accuracy: 0.8409 - val_loss: 2.7240 - val_accuracy: 0.5470\n",
      "Epoch 217/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.0185 - accuracy: 0.8296 - val_loss: 2.7249 - val_accuracy: 0.5340\n",
      "Epoch 218/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 0.9834 - accuracy: 0.8435 - val_loss: 2.8322 - val_accuracy: 0.5560\n",
      "Epoch 219/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 0.9865 - accuracy: 0.8389 - val_loss: 2.7863 - val_accuracy: 0.5260\n",
      "Epoch 220/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 0.9658 - accuracy: 0.8488 - val_loss: 2.7538 - val_accuracy: 0.5370\n",
      "Epoch 221/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 0.9889 - accuracy: 0.8402 - val_loss: 2.7616 - val_accuracy: 0.5620\n",
      "Epoch 222/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.0011 - accuracy: 0.8363 - val_loss: 2.7633 - val_accuracy: 0.5530\n",
      "Epoch 223/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 1.0138 - accuracy: 0.8316 - val_loss: 2.7253 - val_accuracy: 0.5370\n",
      "Epoch 224/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 0.9795 - accuracy: 0.8430 - val_loss: 2.8105 - val_accuracy: 0.5260\n",
      "Epoch 225/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.9880 - accuracy: 0.8386 - val_loss: 2.8271 - val_accuracy: 0.5350\n",
      "Epoch 226/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 1.0018 - accuracy: 0.8362 - val_loss: 2.8115 - val_accuracy: 0.5460\n",
      "Epoch 227/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 0.9866 - accuracy: 0.8406 - val_loss: 2.7394 - val_accuracy: 0.5530\n",
      "Epoch 228/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 0.9756 - accuracy: 0.8485 - val_loss: 2.7311 - val_accuracy: 0.5560\n",
      "Epoch 229/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.0084 - accuracy: 0.8319 - val_loss: 2.6956 - val_accuracy: 0.5490\n",
      "Epoch 230/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.9902 - accuracy: 0.8424 - val_loss: 2.8369 - val_accuracy: 0.5360\n",
      "Epoch 231/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 0.9931 - accuracy: 0.8453 - val_loss: 2.8045 - val_accuracy: 0.5340\n",
      "Epoch 232/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.9939 - accuracy: 0.8421 - val_loss: 2.8401 - val_accuracy: 0.5450\n",
      "Epoch 233/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 0.9807 - accuracy: 0.8454 - val_loss: 2.8626 - val_accuracy: 0.5360\n",
      "Epoch 234/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 0.9901 - accuracy: 0.8383 - val_loss: 2.8319 - val_accuracy: 0.5330\n",
      "Epoch 235/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.9734 - accuracy: 0.8494 - val_loss: 2.8568 - val_accuracy: 0.5290\n",
      "Epoch 236/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 0.9719 - accuracy: 0.8488 - val_loss: 2.8413 - val_accuracy: 0.5350\n",
      "Epoch 237/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.9794 - accuracy: 0.8469 - val_loss: 2.8860 - val_accuracy: 0.5310\n",
      "Epoch 238/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 0.9754 - accuracy: 0.8478 - val_loss: 2.9011 - val_accuracy: 0.5370\n",
      "Epoch 239/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 0.9781 - accuracy: 0.8458 - val_loss: 2.8626 - val_accuracy: 0.5130\n",
      "Epoch 240/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 0.9615 - accuracy: 0.8504 - val_loss: 2.8326 - val_accuracy: 0.5390\n",
      "Epoch 241/250\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 1.0042 - accuracy: 0.8358 - val_loss: 2.8112 - val_accuracy: 0.5370\n",
      "Epoch 242/250\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.9758 - accuracy: 0.8494 - val_loss: 2.7699 - val_accuracy: 0.5390\n",
      "Epoch 243/250\n",
      "71/71 [==============================] - 7s 96ms/step - loss: 0.9649 - accuracy: 0.8524 - val_loss: 2.8984 - val_accuracy: 0.5290\n",
      "Epoch 244/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 0.9598 - accuracy: 0.8461 - val_loss: 2.9180 - val_accuracy: 0.5360\n",
      "Epoch 245/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 0.9733 - accuracy: 0.8431 - val_loss: 2.9351 - val_accuracy: 0.5180\n",
      "Epoch 246/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 0.9910 - accuracy: 0.8401 - val_loss: 2.7719 - val_accuracy: 0.5400\n",
      "Epoch 247/250\n",
      "71/71 [==============================] - 7s 93ms/step - loss: 0.9799 - accuracy: 0.8422 - val_loss: 2.8386 - val_accuracy: 0.5410\n",
      "Epoch 248/250\n",
      "71/71 [==============================] - 7s 95ms/step - loss: 0.9608 - accuracy: 0.8470 - val_loss: 2.9184 - val_accuracy: 0.5290\n",
      "Epoch 249/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 0.9794 - accuracy: 0.8441 - val_loss: 2.8314 - val_accuracy: 0.5620\n",
      "Epoch 250/250\n",
      "71/71 [==============================] - 7s 94ms/step - loss: 0.9641 - accuracy: 0.8485 - val_loss: 2.8766 - val_accuracy: 0.5450\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 250\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "\n",
    "# To data augment or not to data augment\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "grsTgGTxQv1m",
    "outputId": "b85e30cb-221c-4fae-e5bb-dd59819e6954"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To visualize the data performance of our model\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tplt.subplot(211)\n",
    "\tplt.title('Cross Entropy Loss')\n",
    "\tplt.plot(history.history['loss'], color='blue', label='train')\n",
    "\tplt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tplt.subplot(212)\n",
    "\tplt.title('Classification Accuracy')\n",
    "\tplt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tplt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = \"SGD1_epochs125_batches128\"\n",
    "\tplt.savefig(filename + '_plot.png')\n",
    " \n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "pL1_LzbGaJg4",
    "outputId": "ebfde2d0-9faf-481f-e7d1-a8d702018345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /content/saved_models/cifar_10_NGB_1_v0_0.h5 \n",
      "1000/1000 [==============================] - 0s 193us/step\n",
      "Test loss: 1.9333054094314575\n",
      "Test accuracy: 0.5460000038146973\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights very important\n",
    "# To load model use load_model()\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar_10_NGB_1_v0_0.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tI1jLnl28tzc"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(my_predict)\n",
    "predict_Format = pd.read_csv(INPUT + \"Sample_submission.csv\")\n",
    "for i in range(len(prediction)):\n",
    "  predict_Format[\"Test Label\"][i] = myLabels[prediction[i]]\n",
    "predict_Format.to_csv('predict.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "142_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
